{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring TEACh Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from teach.dataset.definitions import Definitions\n",
    "from teach.dataset.dataset import Dataset\n",
    "from teach.dataset.actions import Action_Keyboard, Action_ObjectInteraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit data directory if changed when using `teach_download`\n",
    "# data_dir = \"/tmp/teach-dataset\"\n",
    "data_dir = \"/data/anthony/teach\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a `Definitions` object to access various definitions, mappings of agent IDs and actions to names, as well as task definitions. \n",
    "The code uses `Driver` when referring to the `Follower` in the paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent IDs to agents:  OrderedDict([(0, OrderedDict([('agent_name', 'Commander'), ('agent_type', 0)])), (1, OrderedDict([('agent_name', 'Driver'), ('agent_type', 1)]))])\n",
      "Status IDs to names:  OrderedDict([(0, 'Success'), (1, 'Failure')])\n"
     ]
    }
   ],
   "source": [
    "definitions = Definitions(version=\"2.0\")\n",
    "print(\"Agent IDs to agents: \", definitions.map_agents_id2info)\n",
    "print(\"Status IDs to names: \", definitions.map_status_id2name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display mappings of action IDs to action names. Note that only a subset of these are used in TEACh data. Note that `definitions.map_tasks_name2info` ends up being more useful when trying to access actions by name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action IDs to names:\n",
      "\t  0 : Stop\n",
      "\t  1 : Move to\n",
      "\t  2 : Forward\n",
      "\t  3 : Backward\n",
      "\t  4 : Turn Left\n",
      "\t  5 : Turn Right\n",
      "\t  6 : Look Up\n",
      "\t  7 : Look Down\n",
      "\t  8 : Pan Left\n",
      "\t  9 : Pan Right\n",
      "\t  10 : Move Up\n",
      "\t  11 : Move Down\n",
      "\t  12 : Double Forward\n",
      "\t  13 : Double Backward\n",
      "\t  300 : Navigation\n",
      "\t  200 : Pickup\n",
      "\t  201 : Place\n",
      "\t  202 : Open\n",
      "\t  203 : Close\n",
      "\t  204 : ToggleOn\n",
      "\t  205 : ToggleOff\n",
      "\t  206 : Slice\n",
      "\t  207 : Dirty\n",
      "\t  208 : Clean\n",
      "\t  209 : Fill\n",
      "\t  210 : Empty\n",
      "\t  211 : Pour\n",
      "\t  212 : Break\n",
      "\t  400 : BehindAboveOn\n",
      "\t  401 : BehindAboveOff\n",
      "\t  500 : OpenProgressCheck\n",
      "\t  501 : SelectOid\n",
      "\t  502 : SearchObject\n",
      "\t  100 : Text\n",
      "\t  101 : Speech\n",
      "\t  102 : Beep\n"
     ]
    }
   ],
   "source": [
    "print(\"Action IDs to names:\")\n",
    "for action_id, action in definitions.map_actions_id2info.items():\n",
    "    print(\"\\t \", action_id, \":\", action[\"action_name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks are also most convenient to access by name via `definitions.map_tasks_name2info` but can be accessed via ID using `definitions.map_tasks_id2info`. The values of both of these dictionaries are of type `Task_THOR`.  \n",
    "\n",
    "When a `Definitions` object is instantiated, all tasks defined under `src/teach/meta_data_files/task_definitions` get loaded. The Task Definition Language is explained in Appendix F of the [TEACh paper](https://arxiv.org/pdf/2110.00534.pdf). To create a new task, create a new JSON file under `src/teach/meta_data_files/task_definitions`. Each task needs to have a unique `task_id` and `task_name`. Tasks can be referenced in other tasks by their `task_name`. After creating a new task, test that it can be loaded any any inter-task dependencies can be resolved by instantiating a `Definitions` object.\n",
    "\n",
    "The following code snippet demonstrates how to print a few task details. Note that `#n` (where `n` is a number) indicates a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task details by name:\n",
      "Task name                         Task ID    Num task params      Task component names\n",
      "Sandwich                            302             2          ['toast', 'lettuce', 'tomato', 'plate']\n",
      "Water Plant                         114             0          ['water_plant']\n",
      "Basic Bathroom Tasks                403             0          ['faucets', 'candles', 'soap', 'counter']\n",
      "Boil X                              112             1          ['boiled_#0']\n",
      "Coffee                              102             0          ['coffee']\n",
      "Workspace                           305             3          ['writing', 'laptop', 'book', 'gather_spot', 'lights']\n",
      "Poach Egg                           113             0          ['poached_egg']\n",
      "N Slices Of X In Y                  108             4          ['#1', '#3']\n",
      "Sliced X                            104             1          ['#0', 'knife']\n",
      "Candles                             304             0          ['candles', 'bathtub']\n",
      "Plate Of Toast                      106             0          ['toast', 'plate']\n",
      "Toast                               101             0          ['toast']\n",
      "Put All X In One Y                  111             3          ['#0', '#2']\n",
      "Clean X                             103             1          ['#0', 'sink']\n",
      "Custom Properties Kitchen Tasks     405             0          ['boiled_potato', 'poached_egg']\n",
      "N Cooked Slices Of X In Y           107             4          ['#1', '#3']\n",
      "Put All X On Y                      110             3          ['#0', '#2']\n",
      "Toggle X All Y                      116             3          ['#1']\n",
      "Basic Kitchen Tasks                 401             0          ['coffee', 'toast', 'omelette', 'spatula', 'drawer']\n",
      "Breakfast                           301             14         ['coffee', 'toast', 'potatoes', 'apple', 'sandwich', 'salad', 'serving_spot']\n",
      "Clean All X                         115             1          ['#0', 'sink']\n",
      "Tutorial                            201             0          ['coffee', 'potato']\n",
      "Cooked Slice Of X                   105             1          ['#0', 'knife']\n",
      "Omelette                            109             0          ['omelette']\n",
      "Salad                               303             3          ['lettuce', 'tomato', 'potato', 'plate']\n"
     ]
    }
   ],
   "source": [
    "print(\"Task details by name:\")\n",
    "print(\"Task name\".ljust(33, \" \"), \"Task ID\".ljust(10, \" \"), \"Num task params\".ljust(20, \" \"), \"Task component names\")\n",
    "for task_name, task in definitions.map_tasks_name2info.items():\n",
    "    print(\n",
    "        task_name.ljust(35, \" \"),\n",
    "        str(task.task_id).ljust(15, \" \"),\n",
    "        str(task.task_nparams).ljust(10, \" \"),\n",
    "        str(list(task.components.keys())),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gameplay Sessions\n",
    "Gameplay sessions are stored in `json` files. The `games` subdirectory consists of one subdirectory per split each containing game files of that split. When loaded, these are dictionaries and for many purposes, it is sufficient to analyze the dictionaries. Some examples:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['version', 'task_type', 'comments', 'definitions', 'tasks'])\n"
     ]
    }
   ],
   "source": [
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)\n",
    "print(game_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the game dictionary contains other keys, the important one is `tasks`. `version`, `task_type` and `comments` are dataset-specific metadata, and `definitions` contains the version of the `Definitions` object used to collect the data. However, all games in the subdirectory `games` have been verified to be replayable and resulting in task success using the current (released) version of the `Definitions` object. `tasks` is always a list of length 1 in this dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['task_id', 'task_name', 'task_params', 'task_nparams', 'task_anchor_object', 'desc', 'components', 'relations', 'comments', 'episodes'])\n"
     ]
    }
   ],
   "source": [
    "print(game_dict[\"tasks\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary that can be converted to a `Task_THOR` object. All keys except `episodes` are associated with the task definition and can be better understood by reading Appendix F of the [TEACh paper](https://arxiv.org/pdf/2110.00534.pdf). For all game files in this dataset `game_dict['tasks'][0]['episodes']` will be a list of length 1 and `game_dict['tasks'][0]['episodes'][0]` contains the actual sequence of actions taken in the episode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['episode_id', 'world', 'world_type', 'commander_embodied', 'initial_state', 'interactions', 'final_state'])\n"
     ]
    }
   ],
   "source": [
    "print(game_dict[\"tasks\"][0][\"episodes\"][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Episodes are used to store the initial and final simulator state, as well as the sequence of actions taken in a gameplay session. The components of an episode are:\n",
    "* `episode_id` - A unique id\n",
    "* `world_type` - Type of room which is one of `Kitchen`, `Bedroom`, `Bathroom` and `Living room` \n",
    "* `world` - ID of the specific AI2-THOR floor plan used for this gameplay session\n",
    "* `commander_embodied` - False for all TEACh games\n",
    "* `initial_state`, `final_state` - Dictionaries consisting of the initial and final state of the world including\n",
    "    * `time_start` - \n",
    "    * `agents` - Position and orientation of each agent/ camera at start and end of episode\n",
    "    * `objects` - A list of the state of all objects at the start and end of the episode. Each object is represented by a dictionary whose keys are property names and values are property values.\n",
    "    * `custom_object_metadata` - A dictionary to track custom properties in our codebase that are not present in AI2-THOR. This is a dictionary with AI2-THOR objectId as key and a dictionary of (custom_property_name, custom_property_value) pairs as values\n",
    "* `interactions` - An ordered list of interactions that occurred in the environment, each represented by a dictionary of\n",
    "    * `agent_id` - The agent that took the action\n",
    "    * `action_id` - Which action was taken\n",
    "    * `time_start` - Duration of time between start of episode and when this action started\n",
    "    * `duration` - Duration of time (in sec) taken to execute this action\n",
    "    * `success` - 1 if the action was successfully executed during data collection and 0 otherwise. An example of a case where `success` might be 0 is if the human annotator tried to pick up an object from too far away \n",
    "    * Action specific keys. Some examples include\n",
    "        * `utterance` for a `Text` action - Stores the text value of the utterance made\n",
    "        * `pose_delta` and `pose` for a navigation action\n",
    "        \n",
    "Code snippet to print out the sequence of actions taken in an episode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_actions_from_game_dict(game_dict, definitions):\n",
    "    interactions = game_dict[\"tasks\"][0][\"episodes\"][0][\"interactions\"]\n",
    "    print(\n",
    "        \"Time Start\",\n",
    "        \"Action Success\".ljust(15, \" \"),\n",
    "        \"Agent\".ljust(15, \" \"),\n",
    "        \"Action\".ljust(20, \" \"),\n",
    "        \"Utterance text / Object ID / Object X, Y\",\n",
    "    )\n",
    "    for interaction in interactions:\n",
    "        output_str = \"\".rjust(2, \" \")\n",
    "        output_str += (\"%.2f\" % interaction[\"time_start\"]).ljust(15, \" \")\n",
    "        output_str += str(interaction[\"success\"]).ljust(10, \" \")\n",
    "        output_str += definitions.map_agents_id2info[interaction[\"agent_id\"]][\"agent_name\"].ljust(15, \" \")\n",
    "        output_str += definitions.map_actions_id2info[interaction[\"action_id\"]][\"action_name\"].ljust(20, \" \")\n",
    "        if \"utterance\" in interaction:\n",
    "            output_str += interaction[\"utterance\"]\n",
    "        elif \"oid\" in interaction and interaction[\"oid\"] is not None:\n",
    "            output_str += interaction[\"oid\"]\n",
    "        elif \"x\" in interaction and \"y\" in interaction:\n",
    "            output_str += \"(\" + str(interaction[\"x\"]) + \", \" + str(interaction[\"y\"]) + \")\"\n",
    "        print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Start Action Success  Agent           Action               Utterance text / Object ID / Object X, Y\n",
      "  15.29          0         Commander      OpenProgressCheck   \n",
      "  27.85          1         Commander      Text                I need the newspaper to be placed on a single table.\n",
      "  29.49          1         Commander      SelectOid           \n",
      "  39.11          1         Driver         Text                what should i do\n",
      "  61.21          1         Driver         Pan Left            \n",
      "  61.59          1         Driver         Pan Left            \n",
      "  61.84          1         Driver         Pan Left            \n",
      "  62.12          1         Commander      Text                I need the newspaper placed on a single table.\n",
      "  70.16          1         Driver         Pickup              Newspaper|-04.15|+00.36|-02.48\n",
      "  87.74          1         Driver         Place               CoffeeTable|-02.47|+00.00|-02.49\n",
      "  92.55          1         Commander      OpenProgressCheck   \n"
     ]
    }
   ],
   "source": [
    "print_actions_from_game_dict(game_dict, definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for all object interactions, the relative coordinates of the object on the agent's egocentric image are available in `interaction['x'], interaction['y']`. In the cases where the wrapper was able to resolve these to an object ID using the segmentation frame, we also have the ID of the object interacted with in `interaction['oid']` but if the wrapper was forced to backoff to raycasting, then this is not available.   \n",
    "\n",
    "It is also possible to import a game file into a `Dataset` object as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "game = Dataset.import_json(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is how the code snippet to print out the same action info would look using the object oriented representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_actions_from_game_as_dataset(game, definitions):\n",
    "    interactions = game.tasks[0].episodes[0].interactions\n",
    "    print(\n",
    "        \"Time Start\",\n",
    "        \"Action Success\".ljust(15, \" \"),\n",
    "        \"Agent\".ljust(15, \" \"),\n",
    "        \"Action\".ljust(20, \" \"),\n",
    "        \"Utterance text / Object ID / Object X, Y\",\n",
    "    )\n",
    "    for interaction in interactions:\n",
    "        output_str = \"\".rjust(2, \" \")\n",
    "        output_str += (\"%.2f\" % interaction.time_start).ljust(15, \" \")\n",
    "        output_str += str(interaction.status).ljust(10, \" \")\n",
    "        output_str += definitions.map_agents_id2info[interaction.agent_id][\"agent_name\"].ljust(15, \" \")\n",
    "        output_str += definitions.map_actions_id2info[interaction.action.action_id][\"action_name\"].ljust(20, \" \")\n",
    "        if isinstance(interaction.action, Action_Keyboard):\n",
    "            output_str += interaction.action.utterance\n",
    "        if isinstance(interaction.action, Action_ObjectInteraction):\n",
    "            if interaction.action.oid is None:\n",
    "                output_str += \"(\" + str(interaction.action.x) + \", \" + str(interaction.action.y) + \")\"\n",
    "            else:\n",
    "                output_str += interaction.action.oid\n",
    "        print(output_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Start Action Success  Agent           Action               Utterance text / Object ID / Object X, Y\n",
      "  15.29          None      Commander      OpenProgressCheck   \n",
      "  27.85          None      Commander      Text                I need the newspaper to be placed on a single table.\n",
      "  29.49          None      Commander      SelectOid           \n",
      "  39.11          None      Driver         Text                what should i do\n",
      "  61.21          None      Driver         Pan Left            \n",
      "  61.59          None      Driver         Pan Left            \n",
      "  61.84          None      Driver         Pan Left            \n",
      "  62.12          None      Commander      Text                I need the newspaper placed on a single table.\n",
      "  70.16          None      Driver         Pickup              Newspaper|-04.15|+00.36|-02.48\n",
      "  87.74          None      Driver         Place               CoffeeTable|-02.47|+00.00|-02.49\n",
      "  92.55          None      Commander      OpenProgressCheck   \n"
     ]
    }
   ],
   "source": [
    "print_actions_from_game_as_dataset(game, definitions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while the object oriented representation of the game can be manipulated more easily in the code, the task of the game does not get perfectly loaded. Specifically, when loading a game file, no attempt is made to resolve components of tasks that are themselves tasks. Additionally, the final state does not get loaded. The following code snippet shows how to check whether the task associated with a gameplay session is complete at the final state, by directly loading the game json file as a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "definitions = Definitions(version=\"2.0\")\n",
    "f = os.path.join(data_dir, \"games/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)\n",
    "game_task = game_dict[\"tasks\"][0]\n",
    "task_to_check = copy.deepcopy(\n",
    "    definitions.map_tasks_name2info[game_task[\"task_name\"]]\n",
    ")  # Copying is important if you're sharing a definitions object across calls\n",
    "task_to_check.task_params = game_task[\"task_params\"]\n",
    "final_state_objects = game_dict[\"tasks\"][0][\"episodes\"][0][\"final_state\"][\"objects\"]\n",
    "task_check_output = task_to_check.check_episode_progress(final_state_objects)\n",
    "print(task_check_output[\"success\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stitch video? \n",
    "# Show some frames, progresscheck, image features \n",
    "# TATCDataset?\n",
    "\n",
    "\n",
    "definitions = Definitions(version=\"2.0\")\n",
    "f = os.path.join(data_dir, \"games_final/train/7d2a79f43e605c36_1657.game.json\")\n",
    "with open(f) as h:\n",
    "    game_dict = json.load(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent_id': 0,\n",
       " 'action_id': 500,\n",
       " 'time_start': 15.29451847076416,\n",
       " 'duration': 1,\n",
       " 'success': 0,\n",
       " 'query': '',\n",
       " 'commander_obs': '/images/train/7d2a79f43e605c36_1657/commander.frame.15.29451847076416.jpeg',\n",
       " 'driver_obs': '/images/train/7d2a79f43e605c36_1657/driver.frame.15.29451847076416.jpeg',\n",
       " 'pc_json': '/prog_check_files/train/PC/7d2a79f43e605c36_1657/progresscheck.status.15.29451847076416.json'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_dict['tasks'][0]['episodes'][0]['interactions'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "from modeling.datasets.tatc import TATCDataset\n",
    "from modeling.utils.helper_util import AttrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MainThread-3239212-INFO] modeling.datasets.base: Visual checkpoint for data preprocessing: /data/anthony/teach/experiments/checkpoints/pretrained/fasterrcnn_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling.datasets.base:Visual checkpoint for data preprocessing: /data/anthony/teach/experiments/checkpoints/pretrained/fasterrcnn_model.pth\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MainThread-3239212-INFO] modeling.datasets.base: train dataset size = 1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling.datasets.base:train dataset size = 1482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MainThread-3239212-INFO] modeling.utils.data_util: In load_vocab, loading vocab from /data/anthony/teach/tatc_final/data.vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling.utils.data_util:In load_vocab, loading vocab from /data/anthony/teach/tatc_final/data.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MainThread-3239212-INFO] modeling.datasets.tatc: Loading object vocab from /home/anthony/teach/src/teach/modeling/vocabs/obj_cls.vocab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:modeling.datasets.tatc:Loading object vocab from /home/anthony/teach/src/teach/modeling/vocabs/obj_cls.vocab\n"
     ]
    }
   ],
   "source": [
    "args = AttrDict(\n",
    "    fast_epoch=False,\n",
    "    model=\"seq2seq_attn\",\n",
    "    lmdb_max_readers=1,\n",
    "    no_lang=False,\n",
    "    no_vision=False,\n",
    "    compute_train_loss_over_history=True\n",
    ")\n",
    "\n",
    "dataset = TATCDataset(\"tatc_final\", \"train\", args, ann_type=\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': Vocab(2705), 'driver_action_low': Vocab(22), 'driver_action_high': Vocab(108), 'commander_action_low': Vocab(14), 'object_cls': Vocab(101)}\n",
      "Commander Actions\n",
      "['OpenProgressCheck',\n",
      " 'SelectOid',\n",
      " 'SearchObject',\n",
      " 'Text',\n",
      " 'NoOp',\n",
      " 'Look Up',\n",
      " 'Pan Right',\n",
      " 'Turn Left',\n",
      " 'Turn Right',\n",
      " 'Forward',\n",
      " 'Pan Left',\n",
      " 'Backward',\n",
      " 'Look Down',\n",
      " 'Navigation']\n",
      "Follower Actions\n",
      "['Stop',\n",
      " 'Forward',\n",
      " 'Backward',\n",
      " 'Turn Left',\n",
      " 'Turn Right',\n",
      " 'Look Up',\n",
      " 'Look Down',\n",
      " 'Pan Left',\n",
      " 'Pan Right',\n",
      " 'Navigation',\n",
      " 'Pickup',\n",
      " 'Place',\n",
      " 'Open',\n",
      " 'Close',\n",
      " 'ToggleOn',\n",
      " 'ToggleOff',\n",
      " 'Slice',\n",
      " 'Pour',\n",
      " 'Text',\n",
      " 'NoOp',\n",
      " 'OpenProgressCheck',\n",
      " 'SearchObject']\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.vocab\n",
    "print(vocab)\n",
    "\n",
    "print('Commander Actions')\n",
    "pprint(vocab['commander_action_low'].to_dict()['index2word'])\n",
    "\n",
    "print('Follower Actions')\n",
    "pprint(vocab['driver_action_low'].to_dict()['index2word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (135086472.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_3239212/135086472.py\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    print('Num commander actions: f{len(feat_dict['commander_action'])}', len(feat_dict['driver_action']))\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Every element in the TATCDataset is a tuple containing the game json and a dictionary of features.\n",
    "# The features that we provided include tokenized commander and follower dialogue, commander and follow actions, object (if there is an object interaction) \n",
    "# and visual features extracted using a pretrained vision extractor. \n",
    "task_json, feat_dict = dataset[0]\n",
    "\n",
    "print('Features:')\n",
    "print(list(feat_dict.keys()))\n",
    "\n",
    "\n",
    "print('\\nShape of the visual features:')\n",
    "print(feat_dict['frames'].shape)\n",
    "\n",
    "print('\\nLength of commander and driver language tokens: ')\n",
    "print(len(feat_dict['commander_action']), len(feat_dict['driver_action']))\n",
    "print(len(feat_dict['commander_lang']), len(feat_dict['driver_lang']))\n",
    "\n",
    "print('\\nConverting from tokens to original dialogue:')\n",
    "\n",
    "commander_lang, driver_lang, action_seq = \"\", \"\", \"\"\n",
    "for token in feat_dict['commander_lang']:\n",
    "    commander_lang += vocab['word'].index2word(token) + \" \"\n",
    "\n",
    "for token in feat_dict['driver_lang']:\n",
    "    driver_lang += vocab['word'].index2word(token) + \" \"\n",
    "\n",
    "for i, _ in enumerate(feat_dict['commander_action']):\n",
    "    commander_action = vocab['commander_action_low'].index2word(feat_dict['commander_action'][i])\n",
    "    driver_action = vocab['driver_action_low'].index2word(feat_dict['driver_action'][i])\n",
    "    action_seq += f\"({commander_action}, {driver_action}) -> \"\n",
    "\n",
    "print('\\nCommander dialogue')\n",
    "print(commander_lang)\n",
    "\n",
    "print('\\nDriver dialogue')\n",
    "print(driver_lang)\n",
    "\n",
    "print('\\nAction sequence')\n",
    "print(action_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['commander_lang', 'driver_lang', 'commander_action', 'driver_action', 'object', 'frames'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 66, 12, 5, 66, 12, 51]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict['driver_lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teach",
   "language": "python",
   "name": "teach"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
